batch_size    256
code_file    ptb-lm.py
data    data
debug    False
dp_keep_prob    0.85
emb_size    200
evaluate    False
hidden_size    256
initial_lr    20.0
model    TRANSFORMER
num_epochs    40
num_layers    6
optimizer    SGD
save_best    False
save_dir    /home/windows/c/Users/rapha/Documents/MILA/IFT6135/git/ift6135-rnn/assignment2/TRANSFORMER_SGD_model=TRANSFORMER_optimizer=SGD_initial_lr=20_batch_size=256_seq_len=35_hidden_size=256_num_layers=6_dp_keep_prob=.85_0
seed    1111
seq_len    35
